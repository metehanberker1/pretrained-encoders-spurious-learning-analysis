{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flax\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    FlaxAutoModelForSequenceClassification\n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Enable CUDA optimizations\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "os.environ['FORCE_SAVE_BIN'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicSpansAnalyzer:\n",
    "    def __init__(self, model_name: str, dataset_name: str = 'BoringAnt1793/paired_sentiment_datasets'):\n",
    "        \"\"\"\n",
    "        Initialize the ToxicSpansAnalyzer with a specific model and dataset.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = load_dataset(dataset_name)\n",
    "        \n",
    "        # Initialize tokenizer with optimized settings\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name,\n",
    "            use_fast=True,\n",
    "            model_max_length=256\n",
    "        )\n",
    "        \n",
    "        self.model = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "    def compute_metrics(self, eval_pred: EvalPrediction) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute evaluation metrics for the model.\n",
    "        \"\"\"\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "\n",
    "    def preprocess_dataset(self) -> DatasetDict:\n",
    "        \"\"\"\n",
    "        Preprocess the dataset for training and evaluation while preserving splits.\n",
    "        \"\"\"\n",
    "        def preprocess_function(examples):\n",
    "            return self.tokenizer(\n",
    "                examples[\"sentence\"],\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=256,\n",
    "            )\n",
    "\n",
    "        def preprocess_labels(examples):\n",
    "            examples[\"labels\"] = examples[\"sentiment\"]\n",
    "            return examples\n",
    "\n",
    "        logger.info(\"Starting dataset preprocessing...\")\n",
    "\n",
    "        tokenized_datasets = DatasetDict()\n",
    "\n",
    "        # Process each split individually\n",
    "        for split in ['train_original', 'test_original', 'dev_original']:\n",
    "            if split in self.dataset:\n",
    "                logger.info(f\"Preprocessing split: {split}\")\n",
    "                tokenized_split = self.dataset[split].map(preprocess_function, batched=True)\n",
    "                tokenized_split = tokenized_split.map(preprocess_labels, batched=True)\n",
    "                tokenized_datasets[split] = tokenized_split.remove_columns([\"sentence\", \"batch_id\"])\n",
    "                tokenized_datasets[split].set_format(\"torch\")\n",
    "\n",
    "        logger.info(\"Dataset preprocessing completed.\")\n",
    "        return tokenized_datasets\n",
    "\n",
    "    def save_models(self, output_dir: str, hyperparams: Dict):\n",
    "        \"\"\"\n",
    "        Save the model in multiple formats (PyTorch, TensorFlow, and Flax) \n",
    "        along with hyperparameters and evaluation results.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Saving models to {output_dir}\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Save hyperparameters and evaluation results\n",
    "        hyperparams_path = os.path.join(output_dir, \"hyperparameters.json\")\n",
    "        with open(hyperparams_path, 'w') as f:\n",
    "            json.dump(hyperparams, f, indent=4)\n",
    "        \n",
    "        # Save evaluation results\n",
    "        eval_results_path = os.path.join(output_dir, \"eval_results.json\")\n",
    "        with open(eval_results_path, 'w') as f:\n",
    "            json.dump(self.last_eval_results, f, indent=4)\n",
    "\n",
    "        # Save PyTorch model\n",
    "        pytorch_dir = os.path.join(output_dir, \"pytorch\")\n",
    "        os.makedirs(pytorch_dir, exist_ok=True)\n",
    "        # Save explicitly as a .bin file\n",
    "        self.model = self.model.cpu()\n",
    "        torch.save(self.model.state_dict(), os.path.join(output_dir, \"pytorch_model.bin\"))\n",
    "        self.model.save_pretrained(pytorch_dir)\n",
    "\n",
    "        # Save TensorFlow model\n",
    "        try:\n",
    "            tf_dir = os.path.join(output_dir, \"tensorflow\")\n",
    "            os.makedirs(tf_dir, exist_ok=True)\n",
    "            tf_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "                self.model_name, from_pt=True\n",
    "            )\n",
    "            tf_model.save_pretrained(tf_dir)\n",
    "            logger.info(\"TensorFlow model saved successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save TensorFlow model: {str(e)}\")\n",
    "\n",
    "        # Save Flax model\n",
    "        try:\n",
    "            flax_dir = os.path.join(output_dir, \"flax\")\n",
    "            os.makedirs(flax_dir, exist_ok=True)\n",
    "            flax_model = FlaxAutoModelForSequenceClassification.from_pretrained(\n",
    "                self.model_name, from_pt=True\n",
    "            )\n",
    "            flax_model.save_pretrained(flax_dir)\n",
    "            logger.info(\"Flax model saved successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save Flax model: {str(e)}\")\n",
    "\n",
    "        logger.info(\"All models saved successfully.\")\n",
    "\n",
    "    def fine_tune(self, output_dir: str, hyperparams: Dict = None):\n",
    "        \"\"\"\n",
    "        Fine-tune the model with hyperparameter configuration and save results.\n",
    "        \"\"\"\n",
    "        if hyperparams is None:\n",
    "            hyperparams = {'learning_rate': 2e-5, 'batch_size': 32, 'num_epochs': 3}\n",
    "        \n",
    "        # Preprocess the dataset\n",
    "        tokenized_datasets = self.preprocess_dataset()\n",
    "\n",
    "        # Concatenate the validation datasets (test_original and dev_original)\n",
    "        combined_eval_dataset = concatenate_datasets([\n",
    "            tokenized_datasets[\"test_original\"],\n",
    "            tokenized_datasets[\"dev_original\"]\n",
    "        ])\n",
    "\n",
    "        # Store the concatenated dataset under a new key, e.g., \"validation\"\n",
    "        tokenized_datasets[\"validation\"] = combined_eval_dataset\n",
    "\n",
    "        # Initialize the model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            num_labels=2\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Set up the training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=hyperparams['learning_rate'],\n",
    "            per_device_train_batch_size=hyperparams['batch_size'],\n",
    "            per_device_eval_batch_size=hyperparams['batch_size'] * 2,\n",
    "            num_train_epochs=hyperparams['num_epochs'],\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=f\"{output_dir}/logs\",\n",
    "            logging_steps=10,\n",
    "            save_total_limit=2,\n",
    "            fp16=torch.cuda.is_available(),\n",
    "            gradient_checkpointing=True,\n",
    "            dataloader_num_workers=4,\n",
    "            dataloader_pin_memory=True,\n",
    "            push_to_hub=False\n",
    "        )\n",
    "\n",
    "        print(tokenized_datasets)  # This will print the updated dataset with the \"validation\" key\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_datasets[\"train_original\"],\n",
    "            eval_dataset=tokenized_datasets[\"validation\"],  # Use \"validation\" for the concatenated dataset\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=self.compute_metrics\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        logger.info(f\"Starting training with hyperparameters: {hyperparams}\")\n",
    "        train_result = trainer.train()\n",
    "        \n",
    "        # Evaluate the model\n",
    "        logger.info(\"Evaluating model...\")\n",
    "        eval_results = trainer.evaluate()\n",
    "        self.last_eval_results = eval_results\n",
    "\n",
    "        return train_result, eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search(\n",
    "    model_name: str,\n",
    "    learning_rates: List[float],\n",
    "    batch_sizes: List[int],\n",
    "    base_output_dir: str\n",
    ") -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Perform a hyperparameter search to find the best configuration.\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_config = None\n",
    "    best_results = None\n",
    "    \n",
    "    # Create a list to track all configurations and their performance\n",
    "    all_configurations = []\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for bs in batch_sizes:\n",
    "            logger.info(f\"Testing learning rate: {lr}, batch size: {bs}\")\n",
    "            \n",
    "            try:\n",
    "                # Clear CUDA cache if available\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                # Create analyzer and preprocess dataset\n",
    "                analyzer = ToxicSpansAnalyzer(model_name)\n",
    "                \n",
    "                # Prepare hyperparameters for this run\n",
    "                hyperparams = {\n",
    "                    'learning_rate': lr,\n",
    "                    'batch_size': bs,\n",
    "                    'num_epochs': 3,\n",
    "                    'model_name': model_name\n",
    "                }\n",
    "                \n",
    "                # Set output directory for this specific configuration\n",
    "                output_dir = os.path.join(\n",
    "                    base_output_dir, \n",
    "                    f\"{model_name.replace('/', '_')}_lr{lr}_bs{bs}\"\n",
    "                )\n",
    "                \n",
    "                # Fine-tune and evaluate\n",
    "                _, eval_results = analyzer.fine_tune(\n",
    "                    output_dir=output_dir, \n",
    "                    hyperparams=hyperparams\n",
    "                )\n",
    "                \n",
    "                # Extract F1 score\n",
    "                f1_score = eval_results.get(\"eval_f1\", 0)\n",
    "                \n",
    "                # Track all configurations\n",
    "                configuration_result = {\n",
    "                    'hyperparams': hyperparams,\n",
    "                    'f1_score': f1_score,\n",
    "                    'output_dir': output_dir\n",
    "                }\n",
    "                all_configurations.append(configuration_result)\n",
    "                \n",
    "                # Update best configuration if current is better\n",
    "                if f1_score > best_f1:\n",
    "                    best_f1 = f1_score\n",
    "                    best_config = hyperparams\n",
    "                    best_results = eval_results\n",
    "                    \n",
    "                    # Clean up previous best model directory\n",
    "                    best_model_dir = os.path.join(base_output_dir, \"best_model\")\n",
    "                    if os.path.exists(best_model_dir):\n",
    "                        shutil.rmtree(best_model_dir)\n",
    "                    \n",
    "                    # Save the best model with multiple formats\n",
    "                    os.makedirs(best_model_dir, exist_ok=True)\n",
    "                    analyzer.save_models(best_model_dir, hyperparams)\n",
    "                    \n",
    "                    logger.info(f\"New best model saved. F1 Score: {best_f1}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in hyperparameter search for {model_name} (LR:{lr}, BS:{bs}): {str(e)}\")\n",
    "    \n",
    "    # Log and save all configurations for reference\n",
    "    config_log_path = os.path.join(base_output_dir, \"all_configurations.json\")\n",
    "    with open(config_log_path, 'w') as f:\n",
    "        json.dump(all_configurations, f, indent=4)\n",
    "    \n",
    "    logger.info(f\"Best F1 Score: {best_f1}\")\n",
    "    logger.info(f\"Best Configuration: {best_config}\")\n",
    "    \n",
    "    return best_config, best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_model_to_huggingface(\n",
    "    model_path: str, \n",
    "    repo_name: str, \n",
    "    username: str = None,  # Pass username directly\n",
    "    organization: str = None, \n",
    "    private: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload a fine-tuned model to Hugging Face Model Hub.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the local model directory\n",
    "        repo_name (str): Name of the repository to create/update\n",
    "        username (str, optional): Username for upload if not using organization\n",
    "        organization (str, optional): Organization to upload under\n",
    "        private (bool, optional): Whether the repository should be private. Defaults to False.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Hugging Face API\n",
    "        api = HfApi()\n",
    "        \n",
    "        # Determine the full repository name\n",
    "        if username:\n",
    "            full_repo_name = f\"{username}/{repo_name}\"\n",
    "        else:\n",
    "            # If no username or organization provided, raise an error\n",
    "            raise ValueError(\"Must provide either username or organization\")\n",
    "        \n",
    "        # Create the repository if it doesn't exist\n",
    "        try:\n",
    "            api.create_repo(\n",
    "                repo_id=full_repo_name, \n",
    "                private=private,\n",
    "                exist_ok=True  # Won't raise an error if repo already exists\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Repository creation/check failed: {e}\")\n",
    "        \n",
    "        # Upload the entire model directory\n",
    "        api.upload_folder(\n",
    "            folder_path=model_path,\n",
    "            repo_id=full_repo_name,\n",
    "            commit_message=\"Upload fine-tuned toxic spans detection model\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Model successfully uploaded to {full_repo_name}\")\n",
    "        return full_repo_name\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading model to Hugging Face: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_with_hyperparameter_search(\n",
    "    models: List[str],\n",
    "    base_output_dir: str = \"./results\",\n",
    "    learning_rates: List[float] = [1e-5, 2e-5, 3e-5, 5e-5],\n",
    "    batch_sizes: List[int] = [8, 16, 32],\n",
    "    upload_to_hub: bool = False,\n",
    "    organization: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Modified version of run_experiment_with_hyperparameter_search \n",
    "    that includes optional model hub upload.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name in models:\n",
    "        logger.info(f\"Processing model: {model_name}\")\n",
    "        \n",
    "        # Prepare model-specific output directory\n",
    "        model_output_dir = os.path.join(base_output_dir, model_name.replace(\"/\", \"_\"))\n",
    "        \n",
    "        try:\n",
    "            # Perform hyperparameter search\n",
    "            best_config, best_results = hyperparameter_search(\n",
    "                model_name=model_name,\n",
    "                learning_rates=learning_rates,\n",
    "                batch_sizes=batch_sizes,\n",
    "                base_output_dir=model_output_dir\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            results[model_name] = {\n",
    "                \"best_configuration\": best_config,\n",
    "                \"best_results\": best_results\n",
    "            }\n",
    "            \n",
    "            # Optional: Upload to Hugging Face Model Hub\n",
    "            if upload_to_hub:\n",
    "                best_model_dir = os.path.join(base_output_dir, \"best_model\")\n",
    "                \n",
    "                # Create a descriptive repo name\n",
    "                repo_name = f\"cad-{model_name.replace('/', '-')}\"\n",
    "                \n",
    "                # Upload the model\n",
    "                uploaded_repo = upload_model_to_huggingface(\n",
    "                    best_model_dir, \n",
    "                    repo_name, \n",
    "                    username='charleyisballer',\n",
    "                    private=False  # Set to False if you want a public repo\n",
    "                )\n",
    "                \n",
    "                # Add uploaded repo information to results\n",
    "                if uploaded_repo:\n",
    "                    results[model_name][\"uploaded_repo\"] = uploaded_repo\n",
    "            \n",
    "            logger.info(f\"Best configuration for {model_name}: {best_config}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing model {model_name}: {str(e)}\")\n",
    "            results[model_name] = {\"error\": str(e)}\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting BERT experiments...\n",
      "INFO:__main__:Processing model: lyeonii/bert-tiny\n",
      "INFO:__main__:Testing learning rate: 0.001, batch size: 8\n",
      "INFO:__main__:Using device: cpu\n",
      "INFO:__main__:Starting dataset preprocessing...\n",
      "INFO:__main__:Preprocessing split: train_original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e468f11e61784c43b6b9b252bdf3fa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3414 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9199629c50dd42d2b0c603a715229d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3414 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing split: test_original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37daac57519d4765b4b6d1d32efdab5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/976 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3de490d126430390e2b0cbb989cf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/976 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing split: dev_original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b13fb64a07484980f0e29a2058ac13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55344405fe17403dae2edfed8c74049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataset preprocessing completed.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at lyeonii/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/charley/Programming/ucla/cs260d/project/huggingface/new/.venv/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/gg/7n0jp1r94z564swcxk0rk4w40000gn/T/ipykernel_75208/2070388796.py:169: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train_original: Dataset({\n",
      "        features: ['sentiment', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3414\n",
      "    })\n",
      "    test_original: Dataset({\n",
      "        features: ['sentiment', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 976\n",
      "    })\n",
      "    dev_original: Dataset({\n",
      "        features: ['sentiment', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 490\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentiment', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1466\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting training with hyperparameters: {'learning_rate': 0.001, 'batch_size': 8, 'num_epochs': 3, 'model_name': 'lyeonii/bert-tiny'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa92fc9ab6d44f482fb296d7135ec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6767, 'grad_norm': 1.8583616018295288, 'learning_rate': 0.0009921935987509758, 'epoch': 0.02}\n",
      "{'loss': 0.702, 'grad_norm': 2.136654853820801, 'learning_rate': 0.0009843871975019516, 'epoch': 0.05}\n",
      "{'loss': 0.7252, 'grad_norm': 1.4417407512664795, 'learning_rate': 0.0009765807962529274, 'epoch': 0.07}\n",
      "{'loss': 0.7443, 'grad_norm': 2.0919318199157715, 'learning_rate': 0.0009687743950039032, 'epoch': 0.09}\n",
      "{'loss': 0.7391, 'grad_norm': 2.0357553958892822, 'learning_rate': 0.000960967993754879, 'epoch': 0.12}\n",
      "{'loss': 0.7167, 'grad_norm': 2.2695348262786865, 'learning_rate': 0.0009531615925058548, 'epoch': 0.14}\n",
      "{'loss': 0.7046, 'grad_norm': 1.5810796022415161, 'learning_rate': 0.0009453551912568306, 'epoch': 0.16}\n",
      "{'loss': 0.6923, 'grad_norm': 3.8760757446289062, 'learning_rate': 0.0009375487900078064, 'epoch': 0.19}\n",
      "{'loss': 0.6994, 'grad_norm': 2.3947367668151855, 'learning_rate': 0.0009297423887587822, 'epoch': 0.21}\n",
      "{'loss': 0.7054, 'grad_norm': 0.833946943283081, 'learning_rate': 0.000921935987509758, 'epoch': 0.23}\n",
      "{'loss': 0.679, 'grad_norm': 0.9800316691398621, 'learning_rate': 0.0009141295862607338, 'epoch': 0.26}\n",
      "{'loss': 0.6903, 'grad_norm': 1.5048593282699585, 'learning_rate': 0.0009063231850117096, 'epoch': 0.28}\n",
      "{'loss': 0.7087, 'grad_norm': 2.009089946746826, 'learning_rate': 0.0008985167837626854, 'epoch': 0.3}\n",
      "{'loss': 0.6994, 'grad_norm': 2.244621992111206, 'learning_rate': 0.0008907103825136612, 'epoch': 0.33}\n",
      "{'loss': 0.6378, 'grad_norm': 2.3446061611175537, 'learning_rate': 0.000882903981264637, 'epoch': 0.35}\n",
      "{'loss': 0.6194, 'grad_norm': 1.7756297588348389, 'learning_rate': 0.0008750975800156128, 'epoch': 0.37}\n",
      "{'loss': 0.6703, 'grad_norm': 6.4023966789245605, 'learning_rate': 0.0008672911787665886, 'epoch': 0.4}\n",
      "{'loss': 0.5949, 'grad_norm': 7.527682781219482, 'learning_rate': 0.0008594847775175644, 'epoch': 0.42}\n",
      "{'loss': 0.5775, 'grad_norm': 6.429144382476807, 'learning_rate': 0.0008516783762685401, 'epoch': 0.44}\n",
      "{'loss': 0.521, 'grad_norm': 18.766603469848633, 'learning_rate': 0.000843871975019516, 'epoch': 0.47}\n",
      "{'loss': 0.5103, 'grad_norm': 6.775687217712402, 'learning_rate': 0.0008360655737704918, 'epoch': 0.49}\n",
      "{'loss': 0.674, 'grad_norm': 4.093229293823242, 'learning_rate': 0.0008282591725214676, 'epoch': 0.52}\n",
      "{'loss': 0.5458, 'grad_norm': 5.4292426109313965, 'learning_rate': 0.0008204527712724434, 'epoch': 0.54}\n",
      "{'loss': 0.627, 'grad_norm': 4.40253210067749, 'learning_rate': 0.0008126463700234192, 'epoch': 0.56}\n",
      "{'loss': 0.5596, 'grad_norm': 2.0188260078430176, 'learning_rate': 0.000804839968774395, 'epoch': 0.59}\n",
      "{'loss': 0.634, 'grad_norm': 2.102001190185547, 'learning_rate': 0.0007970335675253708, 'epoch': 0.61}\n",
      "{'loss': 0.6473, 'grad_norm': 1.826280117034912, 'learning_rate': 0.0007892271662763466, 'epoch': 0.63}\n",
      "{'loss': 0.5432, 'grad_norm': 2.9178707599639893, 'learning_rate': 0.0007814207650273224, 'epoch': 0.66}\n",
      "{'loss': 0.5955, 'grad_norm': 3.4339544773101807, 'learning_rate': 0.0007736143637782982, 'epoch': 0.68}\n",
      "{'loss': 0.5769, 'grad_norm': 6.934174537658691, 'learning_rate': 0.000765807962529274, 'epoch': 0.7}\n",
      "{'loss': 0.5924, 'grad_norm': 1.2078955173492432, 'learning_rate': 0.0007580015612802498, 'epoch': 0.73}\n",
      "{'loss': 0.5154, 'grad_norm': 4.413578987121582, 'learning_rate': 0.0007501951600312255, 'epoch': 0.75}\n",
      "{'loss': 0.6714, 'grad_norm': 2.2808992862701416, 'learning_rate': 0.0007423887587822014, 'epoch': 0.77}\n",
      "{'loss': 0.6362, 'grad_norm': 3.4001824855804443, 'learning_rate': 0.0007345823575331772, 'epoch': 0.8}\n",
      "{'loss': 0.5555, 'grad_norm': 3.5747013092041016, 'learning_rate': 0.000726775956284153, 'epoch': 0.82}\n",
      "{'loss': 0.4812, 'grad_norm': 1.5120621919631958, 'learning_rate': 0.0007189695550351288, 'epoch': 0.84}\n",
      "{'loss': 0.7352, 'grad_norm': 0.9291799664497375, 'learning_rate': 0.0007111631537861046, 'epoch': 0.87}\n",
      "{'loss': 0.5139, 'grad_norm': 1.2776086330413818, 'learning_rate': 0.0007033567525370804, 'epoch': 0.89}\n",
      "{'loss': 0.6103, 'grad_norm': 4.503693580627441, 'learning_rate': 0.0006955503512880562, 'epoch': 0.91}\n",
      "{'loss': 0.6034, 'grad_norm': 2.2164371013641357, 'learning_rate': 0.000687743950039032, 'epoch': 0.94}\n",
      "{'loss': 0.6178, 'grad_norm': 5.820627212524414, 'learning_rate': 0.0006799375487900078, 'epoch': 0.96}\n",
      "{'loss': 0.6617, 'grad_norm': 2.8651325702667236, 'learning_rate': 0.0006721311475409836, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1205d2c55aaa4f57a1a81db111c408d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6045970916748047, 'eval_accuracy': 0.713506139154161, 'eval_precision': 0.8682352941176471, 'eval_recall': 0.5034106412005457, 'eval_f1': 0.6373056994818653, 'eval_runtime': 35.9669, 'eval_samples_per_second': 40.76, 'eval_steps_per_second': 2.558, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5925, 'grad_norm': 3.784999132156372, 'learning_rate': 0.0006643247462919594, 'epoch': 1.01}\n",
      "{'loss': 0.561, 'grad_norm': 4.430673122406006, 'learning_rate': 0.0006565183450429351, 'epoch': 1.03}\n",
      "{'loss': 0.6043, 'grad_norm': 8.421415328979492, 'learning_rate': 0.000648711943793911, 'epoch': 1.05}\n",
      "{'loss': 0.5728, 'grad_norm': 21.186262130737305, 'learning_rate': 0.0006409055425448868, 'epoch': 1.08}\n",
      "{'loss': 0.4984, 'grad_norm': 4.485283851623535, 'learning_rate': 0.0006330991412958626, 'epoch': 1.1}\n",
      "{'loss': 0.6351, 'grad_norm': 11.388141632080078, 'learning_rate': 0.0006252927400468384, 'epoch': 1.12}\n",
      "{'loss': 0.5299, 'grad_norm': 6.68835973739624, 'learning_rate': 0.0006174863387978142, 'epoch': 1.15}\n",
      "{'loss': 0.4268, 'grad_norm': 24.764911651611328, 'learning_rate': 0.00060967993754879, 'epoch': 1.17}\n",
      "{'loss': 0.5127, 'grad_norm': 5.483583927154541, 'learning_rate': 0.0006018735362997658, 'epoch': 1.19}\n",
      "{'loss': 0.5437, 'grad_norm': 4.496932506561279, 'learning_rate': 0.0005940671350507416, 'epoch': 1.22}\n",
      "{'loss': 0.5059, 'grad_norm': 4.242805004119873, 'learning_rate': 0.0005862607338017174, 'epoch': 1.24}\n",
      "{'loss': 0.4916, 'grad_norm': 5.826972007751465, 'learning_rate': 0.0005784543325526932, 'epoch': 1.26}\n",
      "{'loss': 0.4723, 'grad_norm': 28.252405166625977, 'learning_rate': 0.000570647931303669, 'epoch': 1.29}\n",
      "{'loss': 0.5098, 'grad_norm': 3.572946071624756, 'learning_rate': 0.0005628415300546448, 'epoch': 1.31}\n",
      "{'loss': 0.5574, 'grad_norm': 4.662898540496826, 'learning_rate': 0.0005550351288056205, 'epoch': 1.33}\n",
      "{'loss': 0.4629, 'grad_norm': 2.041250228881836, 'learning_rate': 0.0005472287275565964, 'epoch': 1.36}\n",
      "{'loss': 0.5403, 'grad_norm': 7.298677921295166, 'learning_rate': 0.0005394223263075722, 'epoch': 1.38}\n",
      "{'loss': 0.4904, 'grad_norm': 2.431448221206665, 'learning_rate': 0.000531615925058548, 'epoch': 1.41}\n",
      "{'loss': 0.6839, 'grad_norm': 1.06110417842865, 'learning_rate': 0.0005238095238095238, 'epoch': 1.43}\n",
      "{'loss': 0.5986, 'grad_norm': 1.9691975116729736, 'learning_rate': 0.0005160031225604996, 'epoch': 1.45}\n",
      "{'loss': 0.5978, 'grad_norm': 1.9781758785247803, 'learning_rate': 0.0005081967213114754, 'epoch': 1.48}\n",
      "{'loss': 0.5171, 'grad_norm': 4.32866907119751, 'learning_rate': 0.0005003903200624512, 'epoch': 1.5}\n",
      "{'loss': 0.4717, 'grad_norm': 2.2127108573913574, 'learning_rate': 0.000492583918813427, 'epoch': 1.52}\n",
      "{'loss': 0.5937, 'grad_norm': 6.850520610809326, 'learning_rate': 0.0004847775175644028, 'epoch': 1.55}\n",
      "{'loss': 0.4454, 'grad_norm': 5.037066459655762, 'learning_rate': 0.0004769711163153786, 'epoch': 1.57}\n",
      "{'loss': 0.6779, 'grad_norm': 3.202561140060425, 'learning_rate': 0.00046916471506635443, 'epoch': 1.59}\n",
      "{'loss': 0.574, 'grad_norm': 1.5438380241394043, 'learning_rate': 0.00046135831381733023, 'epoch': 1.62}\n",
      "{'loss': 0.4398, 'grad_norm': 1.3833523988723755, 'learning_rate': 0.00045355191256830603, 'epoch': 1.64}\n",
      "{'loss': 0.4417, 'grad_norm': 3.6079282760620117, 'learning_rate': 0.00044574551131928183, 'epoch': 1.66}\n",
      "{'loss': 0.5596, 'grad_norm': 3.7200253009796143, 'learning_rate': 0.00043793911007025763, 'epoch': 1.69}\n",
      "{'loss': 0.4715, 'grad_norm': 0.663439929485321, 'learning_rate': 0.0004301327088212334, 'epoch': 1.71}\n",
      "{'loss': 0.5273, 'grad_norm': 3.0824835300445557, 'learning_rate': 0.00042232630757220923, 'epoch': 1.73}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define models and hyperparameters\n",
    "    BERT_MODELS = [\n",
    "        \"lyeonii/bert-tiny\",\n",
    "        \"lyeonii/bert-small\",\n",
    "        \"lyeonii/bert-medium\",\n",
    "        \"google-bert/bert-base-uncased\",\n",
    "        \"google-bert/bert-large-uncased\"\n",
    "        \"lyeonii/bert-mini\"\n",
    "    ]\n",
    "    \n",
    "    ROBERTA_MODELS = [\n",
    "        \"smallbenchnlp/roberta-small\",\n",
    "        \"JackBAI/roberta-medium\",\n",
    "        \"FacebookAI/roberta-base\",\n",
    "        \"FacebookAI/roberta-large\"\n",
    "    ]\n",
    "\n",
    "    # Set up base output directory\n",
    "    base_output_dir = \"./cad_results\"\n",
    "    \n",
    "    # Run experiments\n",
    "    logger.info(\"Starting BERT experiments...\")\n",
    "    bert_results = run_experiment_with_hyperparameter_search(\n",
    "        models=BERT_MODELS,\n",
    "        base_output_dir=os.path.join(base_output_dir, \"bert\"),\n",
    "        learning_rates=[1e-3, 1e-4, 1e-5, 1e-2],\n",
    "        batch_sizes=[8, 16],\n",
    "        upload_to_hub=True,\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Starting RoBERTa experiments...\")\n",
    "    roberta_results = run_experiment_with_hyperparameter_search(\n",
    "        models=ROBERTA_MODELS,\n",
    "        base_output_dir=os.path.join(base_output_dir, \"roberta\"),\n",
    "        learning_rates=[1e-3, 1e-4, 1e-5, 1e-2],\n",
    "        batch_sizes=[8, 16],\n",
    "        upload_to_hub=True,\n",
    "    )\n",
    "\n",
    "    logger.info(\"Starting RoBERTa experiments...\")\n",
    "    roberta_results = run_experiment_with_hyperparameter_search(\n",
    "        models=ROBERTA_MODELS,\n",
    "        base_output_dir=os.path.join(base_output_dir, \"roberta\"),\n",
    "        learning_rates=[1e-3, 1e-4, 1e-5, 1e-2],\n",
    "        batch_sizes=[8, 16],\n",
    "        upload_to_hub=True,\n",
    "    )\n",
    "    \n",
    "    # Save overall results\n",
    "    results_path = os.path.join(base_output_dir, \"experiment_results.json\")\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump({\n",
    "            \"bert_results\": bert_results,\n",
    "            \"roberta_results\": roberta_results\n",
    "        }, f, indent=4)\n",
    "    \n",
    "    logger.info(\"Hyperparameter search completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow is using the GPU\")\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        print(f\"Device: {gpu}\")\n",
    "else:\n",
    "    print(\"TensorFlow is not using the GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))  # Should list your GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
